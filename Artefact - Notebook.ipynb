{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML notebook\n",
    "Hi! Welcome to the AutoML notebook. In this notebook you will be enabled to use AutoML in a few steps. \n",
    "1. Upload a raw dataset\n",
    "2. Create a from this raw dataset to do your analysis on\n",
    "3. Let AutoML create a good model for your data a model based on the provided subset\n",
    "\n",
    "To use the notebook in the right way you have to run each code block. Above each code block there is an explanation of what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argwhere, delete\n",
    "from pandas import read_csv, read_sql_table, DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tpot import TPOTClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Upload dataset\n",
    "Upload a raw dataset, this has to be a .csv file. Copy the filepath into the location variable, use two '\\\\' instead of one to make sure that the file is uploade and no error is thrown. Denote the separator of the csv file in the separator variable. examples are commented in the lines below. The top of the dataframe is shown if it is successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>tested_negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>tested_positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  insu  mass   pedi  age            class\n",
       "0     6   148    72    35     0  33.6  0.627   50  tested_positive\n",
       "1     1    85    66    29     0  26.6  0.351   31  tested_negative\n",
       "2     8   183    64     0     0  23.3  0.672   32  tested_positive\n",
       "3     1    89    66    23    94  28.1  0.167   21  tested_negative\n",
       "4     0   137    40    35   168  43.1  2.288   33  tested_positive"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separator = \",\"\n",
    "location = \"C:\\\\Users\\\\riooms\\\\Desktop\\\\dataset_37_diabetes.csv\"\n",
    "separator = ','\n",
    "#location =  'D:\\\\28.5. - RARP - CWZ - ML.csv'\n",
    "df = read_csv(location, sep = separator)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All variables that are not numeric are label-encoded to numeric values in this code section, so that the AutoML method can read your data. The output of this code block is a list with the names of the variables in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['record_id' 'Side' 'epenbni' 'mriece' 'rtsuspect' 'Epstein.new' 'age'\n",
      " 'psad']\n"
     ]
    }
   ],
   "source": [
    "# Categorical boolean mask\n",
    "categorical_feature_mask = df.dtypes==object\n",
    "categorical_cols = df.columns[categorical_feature_mask].tolist()\n",
    "le = LabelEncoder()\n",
    "    # apply le on categorical feature columns\n",
    "if len(categorical_cols) >= 1 :\n",
    "    df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create subsets\n",
    "\n",
    "Copy the column names of the predictor variables to the list and replace the values that are there. Copy the name of the target variable to the corresponding pieces of code. Do not add the target variable to the subset variables, this will cause an error.\n",
    "Run the code blocks to get the subsets ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsetvariables = ['column1' ,'column2', 'column3', 'etc...']\n",
    "subset1variables = ['mriece', 'rtsuspect' ,'Epstein.new' ,'age', 'psad']\n",
    "subset2variables = ['mriece', 'rtsuspect' ,'Epstein.new' ,'age', 'psad']\n",
    "\n",
    "#target = 'class'\n",
    "target = 'epenbni'\n",
    "\n",
    "df.rename(columns={target: 'target'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: create models\n",
    "Run the code below to set the configuration for the creation of your first, automatically created, logistic regression model. The estimated waiting time is 15 minutes a the model to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_config = {\n",
    "    'sklearn.linear_model.LogisticRegression': {\n",
    "        'penalty': [\"l1\", \"l2\"],\n",
    "        'C': [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10., 15., 20., 25.],\n",
    "        'dual': [True, False]\n",
    "    }\n",
    "}\n",
    "\n",
    "tpot1 = TPOTClassifier(generations=10, population_size=50, verbosity=2, \n",
    "                      max_time_mins=7.5, scoring = 'roc_auc',\n",
    "                      config_dict=tpot_config)\n",
    "tpot2 = TPOTClassifier(generations=10, population_size=50, verbosity=2, scoring = 'roc_auc',\n",
    "                      max_time_mins=7.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell to create your first model\n",
    "\n",
    "The AutoML method detects whether there are missing values in your dataset and replaces them with the median value of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943cea1cb8b44cb3bf4f46ad0c6d912c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=50, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.5363209761082102\n",
      "Generation 2 - Current best internal CV score: 0.5363209761082102\n",
      "Generation 3 - Current best internal CV score: 0.543686557729111\n",
      "Generation 4 - Current best internal CV score: 0.5480319365425748\n",
      "Generation 5 - Current best internal CV score: 0.5480319365425748\n",
      "Generation 6 - Current best internal CV score: 0.5781806215848769\n",
      "Generation 7 - Current best internal CV score: 0.5781806215848769\n",
      "Generation 8 - Current best internal CV score: 0.5781806215848769\n",
      "Generation 9 - Current best internal CV score: 0.5929155950432546\n",
      "Generation 10 - Current best internal CV score: 0.5929155950432546\n",
      "Generation 11 - Current best internal CV score: 0.6600345517366794\n",
      "Generation 12 - Current best internal CV score: 0.6726373626373626\n",
      "Generation 13 - Current best internal CV score: 0.6726373626373626\n",
      "Generation 14 - Current best internal CV score: 0.6726373626373626\n",
      "Generation 15 - Current best internal CV score: 0.6726373626373626\n",
      "Generation 16 - Current best internal CV score: 0.6849276491829683\n",
      "Generation 17 - Current best internal CV score: 0.6849276491829683\n",
      "Generation 18 - Current best internal CV score: 0.6849276491829683\n",
      "Generation 19 - Current best internal CV score: 0.6902839477307563\n",
      "Generation 20 - Current best internal CV score: 0.6902839477307563\n",
      "Generation 21 - Current best internal CV score: 0.6902839477307563\n",
      "Generation 22 - Current best internal CV score: 0.6905257232916808\n",
      "Generation 23 - Current best internal CV score: 0.6905257232916808\n",
      "Generation 24 - Current best internal CV score: 0.6905257232916808\n",
      "\n",
      "7.516131116666667 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: LogisticRegression(LogisticRegression(LogisticRegression(LogisticRegression(LogisticRegression(input_matrix, C=5.0, dual=False, penalty=l2), C=20.0, dual=True, penalty=l2), C=1.0, dual=False, penalty=l1), C=25.0, dual=False, penalty=l1), C=20.0, dual=False, penalty=l1)\n",
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08bbaa0213114d2c99f35def58a84716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=50, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.7814806818770398\n",
      "Generation 2 - Current best internal CV score: 0.7854627485680477\n",
      "Generation 3 - Current best internal CV score: 0.7854627485680477\n",
      "Generation 4 - Current best internal CV score: 0.7854627485680477\n",
      "Generation 5 - Current best internal CV score: 0.7854627485680477\n",
      "Generation 6 - Current best internal CV score: 0.7859479998846732\n",
      "Generation 7 - Current best internal CV score: 0.7896552833810332\n",
      "Generation 8 - Current best internal CV score: 0.7920679278360747\n",
      "Generation 9 - Current best internal CV score: 0.7920679278360747\n",
      "Generation 10 - Current best internal CV score: 0.7920679278360747\n",
      "\n",
      "7.50715475 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(BernoulliNB(Normalizer(input_matrix, norm=l1), alpha=1.0, fit_prior=True), bootstrap=True, criterion=gini, max_features=0.5, min_samples_leaf=11, min_samples_split=9, n_estimators=100)\n"
     ]
    }
   ],
   "source": [
    "# rename de targetvariable naar targetvariabele\n",
    "\n",
    "predictorss1 = df[subset1variables]\n",
    "predictorss2 = df[subset2variables]\n",
    "\n",
    "\n",
    "#set train en validatieset op\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(predictorss1, df.target, train_size = 0.75, test_size = 0.25)\n",
    "\n",
    "#train model\n",
    "tpot1.fit(X_train1, Y_train1)\n",
    "score1 = tpot1.score(X_test1, Y_test1)\n",
    "model1 = tpot1._optimized_pipeline\n",
    "\n",
    "#set train en validatieset op\n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(predictorss2, df.target, train_size = 0.75, test_size = 0.25)\n",
    "\n",
    "#train model\n",
    "tpot2.fit(X_train2, Y_train2)\n",
    "score2 = tpot2.score(X_test2, Y_test2)\n",
    "model2 = tpot2._optimized_pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "The next cells can be used to get your model output. Only run these cells when the optimization progress bar is filled!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell to receive the output of your first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model accuracy model 1:  0.678550135501355.  Model used (1): LogisticRegression(LogisticRegression(LogisticRegression(LogisticRegression(LogisticRegression(input_matrix, LogisticRegression__C=5.0, LogisticRegression__dual=False, LogisticRegression__penalty=l2), LogisticRegression__C=20.0, LogisticRegression__dual=True, LogisticRegression__penalty=l2), LogisticRegression__C=1.0, LogisticRegression__dual=False, LogisticRegression__penalty=l1), LogisticRegression__C=25.0, LogisticRegression__dual=False, LogisticRegression__penalty=l1), LogisticRegression__C=20.0, LogisticRegression__dual=False, LogisticRegression__penalty=l1)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Model accuracy model 1:  \" +str(score1) + '.  Model used (1): ' + str(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell to receive the output of your second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model accuracy model 2: 0.7949365979080231.  Model used (2): ExtraTreesClassifier(BernoulliNB(Normalizer(input_matrix, Normalizer__norm=l1), BernoulliNB__alpha=1.0, BernoulliNB__fit_prior=True), ExtraTreesClassifier__bootstrap=True, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.5, ExtraTreesClassifier__min_samples_leaf=11, ExtraTreesClassifier__min_samples_split=9, ExtraTreesClassifier__n_estimators=100)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \"Model accuracy model 2: \" +str(score2) + '.  Model used (2): ' + str(model2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
